# üéôÔ∏è Study - Speech Recognition using Whisper

Seja bem-vindo! O __Reposit√≥rio Speech Recognition - Whisper__ documenta o projeto de reconhecimento de fala em casa utilizando o modelo Whisper. Aqui voc√™ encontrar√° informa√ß√µes detalhadas sobre o projeto, incluindo:

## üìå Navega√ß√£o

- [üìù Sobre o Whisper e SpeechRecognition](#-sobre-o-whisper-e-speechrecognition)
- [üìÅ Estrutura do Reposit√≥rio](#-estrutura-do-reposit√≥rio)
- [üíª Desenvolvimento](#-desenvolvimento)
  - [üîß Ferramentas e tecnologias utilizadas](#-ferramentas-e-tecnologias-utilizadas)
  - [üì• Instala√ß√£o](#-instala√ß√£o)
  - [üöÄ Uso](#-uso)

## üìù Sobre o Whisper e SpeechRecognition

O projeto Speech Recognition - Whisper visa desenvolver um sistema de reconhecimento de fala em casa utilizando o modelo Whisper de √∫ltima gera√ß√£o. O sistema ser√° capaz de:

- __Transcrever √°udio em tempo real:__ O sistema transcrever√° √°udio de conversas, entrevistas, palestras e outros eventos em tempo real, com alta precis√£o.
- __Controlar dispositivos dom√©sticos inteligentes:__ O sistema poder√° ser utilizado para controlar dispositivos dom√©sticos inteligentes por voz, como luzes, TVs, ar-condicionado e muito mais.
- __Realizar tarefas automatizadas:__ O sistema poder√° ser utilizado para realizar tarefas automatizadas, como agendar compromissos, enviar mensagens de texto, tocar m√∫sica e muito mais.

### Sobre o Whisper

Whisper √© um modelo de reconhecimento de fala desenvolvido pela OpenAI. Ele √© capaz de transcrever e traduzir √°udio com alta precis√£o. O modelo √© treinado em uma grande quantidade de dados de √°udio e texto, o que permite que ele funcione bem em uma variedade de idiomas e sotaques.

## üìÅ Estrutura do Reposit√≥rio

Neste reposit√≥rio, voc√™ encontrar√° as seguintes pastas e arquivos:

- `audio_folder/`: Pasta onde os arquivos de √°udio gravados ser√£o armazenados.
- `devices/`: Cont√©m o arquivo `mic_devices.py` que lida com dispositivos de microfone.
- `env/`: Scripts de instala√ß√£o para diferentes sistemas operacionais.
  - `install_whisper_ubuntu.sh`
  - `install_whisper_windows.sh`
- `models/`: Cont√©m os modelos Whisper.
  - `tiny.pt`
- `speech_to_text/`: Cont√©m o arquivo `speech_recogntion.py` que lida com a transcri√ß√£o de √°udio.
- `main.py`: Script principal para executar o projeto.
- `.gitignore`: Arquivo para ignorar arquivos e pastas espec√≠ficas no controle de vers√£o.
- `LICENSE`: Licen√ßa do projeto.
- `README.md`: Este arquivo.

## üíª Desenvolvimento

### üîß Ferramentas e tecnologias utilizadas

- [OpenAI Whisper](https://github.com/openai/whisper)
- Python 3.11
- PyTorch
- Scipy
- Soundfile
- Sounddevice
- FFmpeg
- Setuptools-rust

### üì• Instala√ß√£o

Para instalar as depend√™ncias do projeto, execute os seguintes comandos:

#### Ubuntu

```sh
# OBS: Este script deve ser executado no Python 3.11.9

# Instala a biblioteca scipy
pip install scipy

# Instala a biblioteca soundfile
pip install soundfile

# Instala a biblioteca sounddevice
pip install sounddevice

# Atualiza a biblioteca openai-whisper para a vers√£o mais recente
pip install -U openai-whisper

# Atualiza a lista de pacotes e instala o ffmpeg
sudo apt update && sudo apt install ffmpeg

# Instala a biblioteca setuptools-rust
pip install setuptools-rust
```

#### Windows

```sh
# OBS: Este script deve ser executado no Python 3.11.9

# Instale Chocolatey no PowerShell do Windows
# https://chocolatey.org/install#individual

# Instala a biblioteca scipy
pip install scipy

# Instala a biblioteca soundfile
pip install soundfile

# Instala a biblioteca sounddevice
pip install sounddevice

# Utiliza o Chocolatey para instalar o ffmpeg
choco install ffmpeg

# Atualiza a biblioteca openai-whisper para a vers√£o mais recente
pip install -U openai-whisper
```

### üöÄ Uso

Para utilizar o projeto, siga os passos abaixo:

1. Clone o reposit√≥rio.
2. Instale as depend√™ncias conforme descrito acima.
3. Execute o script `main.py` para iniciar a transcri√ß√£o de √°udio.

```bash
# Clone o reposit√≥rio
git clone https://github.com/rafael-torres-nantes/AtHome-SpeechRecogntion-Whisper.git

# Navegue at√© o diret√≥rio do projeto
cd AtHome-SpeechRecogntion-Whisper

# Instale as depend√™ncias conforme descrito acima
# ...

# Execute o script principal
python main.py
```

#### Exemplo de C√≥digo

Aqui est√° um exemplo de como utilizar o projeto em Python:

```python
import os
from devices.mic_devices import AudioRecording
from speech_to_text.speech_recogntion import SpeechToText

# Exemplo de uso
if __name__ == "__main__":
    # Cria uma inst√¢ncia da classe SpeechToText
    stt = SpeechToText()

    # Carrega o modelo desejado (exemplo: 'tiny')
    stt.load_model(model_name="tiny")

    # Realiza a transcri√ß√£o do √°udio especificado
    try:
        audio_path = "audio_folder/audio_test.wav"

        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"O arquivo de √°udio '{audio_path}' n√£o foi encontrado.")
        
        transcribed_text = stt.transcribe_audio(audio_file=audio_path, 
                                                language="pt", 
                                                task="transcribe", 
                                                verbose=True)

        # Detecta o idioma do √°udio
        detected_language = stt.detect_language(audio_file=audio_path)

        # Realiza a decodifica√ß√£o com op√ß√µes avan√ßadas
        decoded_text = stt.decode_audio(audio_file=audio_path)

    except Exception as e:
        print(f"Erro: {e}")
```
