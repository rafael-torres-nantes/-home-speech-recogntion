# ğŸ™ï¸ AraraBots@AtHome-SpeechRecogntion

Seja bem-vindo !!! O __RepositÃ³rio AtHome-SpeechRecognition-Whisper__ documenta o projeto de reconhecimento de fala em casa utilizando o modelo Whisper. Aqui vocÃª encontrarÃ¡ informaÃ§Ãµes detalhadas sobre o projeto, incluindo:

## ğŸ“Œ NavegaÃ§Ã£o

- [ğŸ“ Sobre o Whisper e SpeechRecognition](#introduÃ§Ã£o)
- [ğŸ“ Estrutura do RepositÃ³rio](#estrutura-do-repositorio)
- [ğŸ’» Desenvolvimento](#desenvolvimento)
  - [ğŸ”§ Ferramentas e tecnologias utilizadas](#ferramentas-e-tecnologias-utilizadas)

 ## ğŸ“Sobre o Whisper e SpeechRecognition

O projeto AtHome-SpeechRecognition-Whisper visa desenvolver um sistema de reconhecimento de fala em casa utilizando o modelo Whisper de Ãºltima geraÃ§Ã£o. O sistema serÃ¡ capaz de:

- __Transcrever Ã¡udio em tempo real:__ O sistema transcreverÃ¡ Ã¡udio de conversas, entrevistas, palestras e outros eventos em tempo real, com alta precisÃ£o.
- __Controlar dispositivos domÃ©sticos inteligentes:__ O sistema poderÃ¡ ser utilizado para controlar dispositivos domÃ©sticos inteligentes por voz, como luzes, TVs, ar-condicionado e muito mais.
- __Realizar tarefas automatizadas:__ O sistema poderÃ¡ ser utilizado para realizar tarefas automatizadas, como agendar compromissos, enviar mensagens de texto, tocar mÃºsica e muito mais.

## ğŸ“ Estrutura do RepositÃ³rio

Neste repositÃ³rio, vocÃª encontrarÃ¡ 3 pastas, sendo elas:
- 3 pastas com os temas da trilha de MÃ©todos Ãgeis;
- 1 arquivo README com o detalhes sobre as informaÃ§Ãµes da trilha;

Cada pasta contÃ©m os arquivos produzidos durante o processo de aprendiza, podendo incluir:
- __assets__ : Pasta que contÃ©m imagens e documentaÃ§Ãµes do processo de aprendizado;
- __src__ : Pasta que contÃ©m os cÃ³digos utilizados durante os estudos;
- -  __tests__: ContÃ©m os testes do projeto.
- __README.md__ : Arquivo de texto que contÃ©m detalhes sobre o projeto;

## ğŸ’» Desenvolvimento

### ğŸ”§ Ferramentas e tecnologias utilizadas

[OpenAi](https://github.com/openai/whisper)
We used Python 3.9.9 and PyTorch 1.10.1 to train and test our models, but the codebase is expected to be compatible with Python 3.8-3.11 and recent PyTorch versions. The codebase also depends on a few Python packages, most notably OpenAI's tiktoken for their fast tokenizer implementation. You can download and install (or update to) the latest release of Whisper with the following command:
```
pip install -U openai-whisper
```

It also requires the command-line tool ffmpeg to be installed on your system, which is available from most package managers:
```
sudo apt update && sudo apt install ffmpeg
```

You may need rust installed as well, in case tiktoken does not provide a pre-built wheel for your platform.
```
pip install setuptools-rust
```

# Install Sounddevice

```
pip install sounddevice
```

(SoundDevice Documentation)[https://readthedocs.org/projects/python-sounddevice/downloads/pdf/latest/]
```
import sounddevice as sd
```

# Install SoundFile

```
pip install soundfile
```
